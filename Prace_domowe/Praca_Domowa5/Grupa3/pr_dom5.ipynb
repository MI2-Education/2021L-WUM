{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"x\",\"y\"]\n",
    "df\n",
    "plt.scatter(df['x'],df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import math\n",
    "from sklearn import metrics\n",
    "def kmeans_stability_mean(df,cluster_num):\n",
    "    n=100\n",
    "    ans=[]\n",
    "    metr=[]\n",
    "    labels_true=KMeans(n_clusters=cluster_num).fit_predict(df)\n",
    "    mean=0\n",
    "    for i in range(n):\n",
    "        bootstrap=resample(df, replace=True, n_samples=math.floor(df.shape[0]*0.8))\n",
    "        model=KMeans(n_clusters=cluster_num)\n",
    "        model.fit(bootstrap)\n",
    "        ans.append( model.predict(df))\n",
    "        metr.append(metrics.adjusted_mutual_info_score(labels_true,ans[i]))\n",
    "        mean+=metr[i]\n",
    "    mean=mean/n\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=[]\n",
    "vec1=[]\n",
    "for i in range(10):\n",
    "    n_clusters=i+1\n",
    "    vec.append(kmeans_stability_mean(df,n_clusters))\n",
    "    vec1.append(n_clusters)\n",
    "plt.plot(vec1,vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą bootstrapa określiliśmy, że najstabilniejszy jest podział na 5 lub 7 klastrów dla KMeans, dlatego postaramy się wybierać ilość klastrów ze zbioru {5,7,8,9}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda łokcia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code copied from laboratory file\n",
    "from scipy.spatial import distance\n",
    "def count_clustering_scores(X, cluster_num, model_class, score_fun):\n",
    "    if isinstance(cluster_num, int):\n",
    "        cluster_num_iter = [cluster_num]\n",
    "    else:\n",
    "        cluster_num_iter = cluster_num\n",
    "    scores = []    \n",
    "    for k in cluster_num_iter:\n",
    "        model_instance = model_class(n_clusters=k)\n",
    "        labels = model_instance.fit_predict(X)\n",
    "        wcss = score_fun(X, labels)\n",
    "        scores.append(wcss)\n",
    "    \n",
    "    if isinstance(cluster_num, int):\n",
    "        return scores[0]\n",
    "    else:\n",
    "        return scores\n",
    "def count_clustering_scores_agl(X, cluster_num, model_class, score_fun):\n",
    "    if isinstance(cluster_num, int):\n",
    "        cluster_num_iter = [cluster_num]\n",
    "    else:\n",
    "        cluster_num_iter = cluster_num\n",
    "    scores = []    \n",
    "    for k in cluster_num_iter:\n",
    "        model_instance = model_class(n_clusters=k,linkage=\"ward\")\n",
    "        labels = model_instance.fit_predict(X)\n",
    "        wcss = score_fun(X, labels)\n",
    "        scores.append(wcss)\n",
    "    \n",
    "    if isinstance(cluster_num, int):\n",
    "        return scores[0]\n",
    "    else:\n",
    "        return scores\n",
    "def mean_dist_to_center(X, label):\n",
    "    clusters = set(label)\n",
    "    inclust_dist_list = []\n",
    "    for cluster_i in clusters:\n",
    "        cluster_i_idx = np.where(label == cluster_i)\n",
    "        cluster_i_mean = np.mean(X[cluster_i_idx], axis=0, keepdims=True)\n",
    "        inclust_dist = np.mean(distance.cdist(X[cluster_i_idx], cluster_i_mean))\n",
    "        inclust_dist_list.append(inclust_dist)\n",
    "    return np.mean(inclust_dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec2=[]\n",
    "vec3=[]\n",
    "for i in range(10):\n",
    "    n_clusters=i+1\n",
    "    vec2.append(count_clustering_scores(np.array(df), n_clusters, KMeans, mean_dist_to_center))\n",
    "    vec3.append(n_clusters)\n",
    "plt.plot(vec3,vec2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą metody łokcia ciężko jest określić optymalną ilość klastrów może to być 2, 4, 6 lub 8. Dlatego spróbujemy metoda silhouette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=[]\n",
    "vec1=[]\n",
    "for i in range(10):\n",
    "    n_clusters=i+2\n",
    "    vec.append(count_clustering_scores(df, n_clusters, KMeans, silhouette_score))\n",
    "    vec1.append(n_clusters)\n",
    "plt.plot(vec1,vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu już łatwo zauważyć, że powinniśmy wybrać 8 klastrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km=KMeans(n_clusters=8)\n",
    "plt.scatter(df['x'],df['y'],c=km.fit_predict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od obliczenia liczby klastrów za pomocą Daviesa- Bouldina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=[]\n",
    "vec1=[]\n",
    "for i in range(10):\n",
    "    n_clusters=i+2\n",
    "    vec.append(count_clustering_scores_agl(df, n_clusters, AgglomerativeClustering, metrics.davies_bouldin_score))\n",
    "    vec1.append(n_clusters)\n",
    "plt.plot(vec1,vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu już łątwo określić optymalną liczbę klastrów -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag=AgglomerativeClustering(n_clusters=6, linkage='ward')\n",
    "plt.scatter(df['x'],df['y'],c=ag.fit_predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
