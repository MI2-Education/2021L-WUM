{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import KNNImputer\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import statistics \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"allegro-api-transactions.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-mason",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-quantity",
   "metadata": {},
   "source": [
    "## Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = ce.TargetEncoder(cols=['it_location'], smoothing=0, return_df=True)\n",
    "\n",
    "df_transformed = encoder1.fit_transform(df, df['price'])\n",
    "df_transformed[\"it_location\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-mineral",
   "metadata": {},
   "source": [
    "One hot encoding może zwrócić wielowymiarową zmieną którą pozwala nam w pewnien sposób zakodować zmienne kategoryczne\n",
    "tak by były łatwiejsze do przetwarzania. Użycie Target encoding pozwala nie tylko na zakodowanie zmiennych ale także\n",
    "zrobienie to w taki sposób by powiązać je z naszym targetem np zamiana lokacji na średnią cenę towarów z tej lokacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-board",
   "metadata": {},
   "source": [
    "## One hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder2 = ce.OneHotEncoder(cols=[\"main_category\"])\n",
    "df_transformed = encoder2.fit_transform(df, df[\"price\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "integer_encoded = le.fit_transform(df.main_category)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[\"main_category\"],drop_first=True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-metadata",
   "metadata": {},
   "source": [
    "## HashingEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = ce.HashingEncoder(cols=[\"main_category\"])\n",
    "df_transformed = encoder3.fit_transform(df, df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.iloc[:,0:9].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-geology",
   "metadata": {},
   "source": [
    "- Na pierwszy rzut oka wygląda podobnie do One Hot Encoding, ale HashingEncoder zwrocił mniej kolumn. Cieżko wieć domyślić się czym są te kolumny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-processing",
   "metadata": {},
   "source": [
    "## CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder4 = ce.CatBoostEncoder(cols=[\"main_category\"])\n",
    "df_transformed = encoder4.fit_transform(df, df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed[\"main_category\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.main_category.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-highland",
   "metadata": {},
   "source": [
    "Wygląda podobnie do target encoding. Dla pierwszych 20 wierszy często pojawia się wartość 76.811350, ale kiedy przyjrzymy się jak wcześniej wyglądała kolumna `main_category` to widzimy że ta wartość nie jest przyporządkowana do jednej kategori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-filling",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"price\", 'it_seller_rating', 'it_quantity']].head(10000)\n",
    "samp =df2['it_seller_rating'].sample(frac=0.1)\n",
    "df_nan = df2\n",
    "df_nan.loc[df_nan.index.isin(samp.index),\"it_seller_rating\"] = None\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-tuner",
   "metadata": {},
   "source": [
    "## Nearest neighbors imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "error1 =[]\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    samp =df2['it_seller_rating'].sample(frac=0.1)\n",
    "    df_nan = df2\n",
    "    df_nan.loc[df_nan.index.isin(samp.index),\"it_seller_rating\"] = None\n",
    "    df2 = df[[\"price\", 'it_seller_rating', 'it_quantity']].head(10000)\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_nni = pd.DataFrame(imputer.fit_transform(df_nan),columns = df_nan.columns)\n",
    "    e = np.sqrt(mean_squared_error(df2, df_nni))\n",
    "    error1.append(e)\n",
    "    \n",
    "statistics.stdev(error1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-following",
   "metadata": {},
   "source": [
    "## Multivariate feature imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "error2 =[]\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    samp =df2['it_seller_rating'].sample(frac=0.1)\n",
    "    df_nan = df2\n",
    "    df_nan.loc[df_nan.index.isin(samp.index),\"it_seller_rating\"] = None\n",
    "    df2 = df[[\"price\", 'it_seller_rating', 'it_quantity']].head(10000)\n",
    "    imputer = IterativeImputer()\n",
    "    imputer.fit(df_nan)\n",
    "    df_ii = pd.DataFrame(imputer.transform(df_nan),columns = df_nan.columns)\n",
    "    e = np.sqrt(mean_squared_error(df2, df_ii))\n",
    "    error2.append(e)\n",
    "    \n",
    "statistics.stdev(error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-resort",
   "metadata": {},
   "source": [
    "## Nearest neighbors imputation - braki w dwóch klumnach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "error3 =[]\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    samp1 =df2['it_seller_rating'].sample(frac=0.1)\n",
    "    samp2 =df2['it_seller_rating'].sample(frac=0.1)\n",
    "    df_nan = df2\n",
    "    df_nan.loc[df_nan.index.isin(samp1.index),\"it_seller_rating\"] = None\n",
    "    df_nan.loc[df_nan.index.isin(samp2.index),\"it_quantity\"] = None\n",
    "    df2 = df[[\"price\", 'it_seller_rating', 'it_quantity']].head(10000)\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_nni = pd.DataFrame(imputer.fit_transform(df_nan),columns = df_nan.columns)\n",
    "    e = np.sqrt(mean_squared_error(df2, df_nni))\n",
    "    error3.append(e)\n",
    "    \n",
    "statistics.stdev(error3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-effects",
   "metadata": {},
   "source": [
    "## Multivariate feature imputation - braki w dwóch kolumnach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "error4 =[]\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    samp1 =df2['it_seller_rating'].sample(frac=0.1)\n",
    "    samp2 =df2['it_seller_rating'].sample(frac=0.1)\n",
    "    df_nan = df2\n",
    "    df_nan.loc[df_nan.index.isin(samp1.index),\"it_seller_rating\"] = None\n",
    "    df_nan.loc[df_nan.index.isin(samp2.index),\"it_quantity\"] = None\n",
    "    df2 = df[[\"price\", 'it_seller_rating', 'it_quantity']].head(10000)\n",
    "    imputer = IterativeImputer()\n",
    "    imputer.fit(df_nan)\n",
    "    df_ii = pd.DataFrame(imputer.transform(df_nan),columns = df_nan.columns)\n",
    "    e = np.sqrt(mean_squared_error(df2, df_ii))\n",
    "    error4.append(e)\n",
    "    \n",
    "statistics.stdev(error4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki = pd.DataFrame([error1,error3,error2,error4])\n",
    "wyniki = wyniki.transpose()\n",
    "wyniki.columns =['NNI-1','NNI-2', 'II-1',  'II-2'] \n",
    "sns.lineplot(data=wyniki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-pavilion",
   "metadata": {},
   "source": [
    "- Mniejsze odchylenie kiedy usuneliśmy dane z 2 kolumn\n",
    "- Multivariate działą szybciej niż nni\n",
    "- Podobne wyniki"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
