{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD 2\n",
    "## Hubert Ruczyński"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(23)\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Część I***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treść\n",
    "\n",
    "Wykonaj target encoding dla zmiennej it_location. Czy i jakie są przewagi target encoding nad one-hot? Jako target traktujemy kolumnę price (będzie to więc zadanie regresji).\n",
    "\n",
    "Zastosuj trzy metody encodingu (one-hot + \"dwie nowe\") dla kolumny main_category. \"Nowe metody\" proszę wybrać spośród wymienionych na stronie https://contrib.scikit-learn.org/category_encoders/. W przypadku, gdy użyta metoda nie działa proszę o stosowną adnotację. Opisz wyniki.\n",
    "\n",
    "Zwizalizuj wynik oraz wyjaśnij czym się różnią sposoby kodowania (czemu to działa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('allegro-api-transactions.csv', index_col='lp')\n",
    "transactions_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transactions_df.loc[:,'it_location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transactions_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=transactions_df.drop('price', axis =1)\n",
    "y=transactions_df.drop('it_location', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['it_location'])\n",
    "encoder.fit(X,y['price'])\n",
    "df_target_encoder=encoder.transform(X,y['price'])\n",
    "df_target_encoder.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_target_encoder.loc[:,'it_location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = ce.OneHotEncoder(handle_unknown='ignore')\n",
    "encoded_onehot = pd.DataFrame(onehot.fit_transform(transactions_df[[\"main_category\"]]))\n",
    "data_onehot = transactions_df.join(encoded_onehot)\n",
    "data_onehot.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspirując się artykułem: https://medium.com/analytics-vidhya/target-encoding-vs-one-hot-encoding-with-simple-examples-276a7e7b3e64, udało mi się wyróżnić proste wady i zalety każdego z kodowań."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHot**\n",
    "\n",
    "*Zalety:*\n",
    "\n",
    "Działa dobrze w przypadku danych nominalnych i eliminuje problem z wyższymi wartościami kategorycznymi wpływającymi na dane, ponieważ tworzymy każdą kolumnę w binarnej 1 lub 0.\n",
    "\n",
    "*Wady:*\n",
    "\n",
    "Może stworzyć bardzo dużą wymiarowość w zależności od liczby posiadanych cech kategorycznych i liczby kategorii na obiekt, co w ostateczności doprowadzić może do bardzo działania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target**\n",
    "\n",
    "*Opis:*\n",
    "\n",
    "Polega na tym, że funkcje są zastępowane połączeniem późniejszego prawdopodobieństwa celu przy danej określonej wartości kategorycznej i wcześniejszego prawdopodobieństwa celu względem wszystkich danych uczących.\n",
    "\n",
    "*Zalety:*\n",
    "\n",
    "Prosta i szybka metoda kodowania, która nie zwiększa wymiarowości zbioru danych.\n",
    "\n",
    "*Wady:*\n",
    "\n",
    "Zależy ono od dystrybucji celu, co oznacza, że wymaga starannej weryfikacji, ponieważ może być podatne na overfitting. Ta metoda jest również specyficzna dla zbioru danych i będzie wykazywać znaczną poprawę tylko przez pewien czas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***OneHotEncoding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=transactions_df.drop('price', axis =1)\n",
    "y3=transactions_df.drop('main_category', axis =1)\n",
    "ce_one_hot = ce.OneHotEncoder(cols = ['main_category'])\n",
    "ce_one_hot_df=ce_one_hot.fit_transform(X3,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_one_hot_df.iloc[:, 11:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHot=ce_one_hot_df.iloc[:, 11:38]\n",
    "OneHot=OneHot.sum()\n",
    "OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars = ('main_category_1', 'main_category_2','main_category_3', 'main_category_4','main_category_5', 'main_category_6','main_category_7', 'main_category_8','main_category_9', 'main_category_10','main_category_11', 'main_category_12','main_category_13', 'main_category_14','main_category_15', 'main_category_16','main_category_17', 'main_category_18','main_category_19', 'main_category_20','main_category_21', 'main_category_22','main_category_23', 'main_category_24','main_category_25','main_category_26','main_category_27')\n",
    "y_pos = np.arange(len(bars))\n",
    "plt.bar(y_pos,OneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda OneHotEncoding działa w ten sposób, że rozdziela zadaną kolumnę na wszystkie unikalne kategorie (kolejne kolumny zamiast tamtej) i następnie dla każdej zmiennej daje 1 w miejscu gdzie chodzi o daną kategorię, a 0 jeśli nie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***LeaveOneOut***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=transactions_df.drop('price', axis =1)\n",
    "y4=transactions_df.drop('main_category', axis =1)\n",
    "ce_leave = ce.LeaveOneOutEncoder(cols = ['main_category'])\n",
    "ce_leave.fit(X4, y4['price'])        \n",
    "ce_leave_df=ce_leave.transform(X4, y4['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave=ce_leave_df.iloc[:, 11:38]\n",
    "leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(leave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodowanie Leave One Out  oblicza średnią zmiennych docelowych dla wszystkich rekordów zawierających tę samą wartość dla danej zmiennej jakościowej. Algorytm kodowania różni się nieco w zestawie danych uczących i testowych. \n",
    "\n",
    "W przypadku zestawu danych uczących omawiany rekord jest pomijany, stąd nazwa Leave One Out. Kodowanie jest następujące dla pewnej wartości określonej zmiennej kategorialnej.\n",
    "\n",
    "W przypadku danych walidacyjnych lub zestawu danych prognozowania definicja jest nieco inna. Nie musimy zostawiać aktualnego rekordu i nie potrzebujemy czynnika losowości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Helmert Encoding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5=transactions_df.drop('price', axis =1)\n",
    "y5=transactions_df.drop('main_category', axis =1)\n",
    "ce_helmert = ce.HelmertEncoder(cols = ['main_category'])\n",
    "ce_helmert_df=ce_helmert .fit_transform(X5, y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helmert=ce_helmert_df.iloc[:, 13:39]\n",
    "helmert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helmert.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=27\n",
    "plt.hist(helmert.max(axis=1), bins=n_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda Helmerta działa w sposób podobny do do OneHotEncoding, gdyż w miejscu w któym mamy do czynienia z n-tą kategorią wstawiana jest liczba n odpowiadająca danej kategorii. Pozostałe kategorie są obsługiwane w taki sposób, że te wcześniejsze otrzymują 0 zaś późniejsze 1.\n",
    "\n",
    "Kodowanie Helmerta jest typem kodowania kategorialnego dla regresji. Porównuje każdy poziom zmiennej kategorialnej ze średnią kolejnych poziomów. Stąd pierwszy kontrast porównuje średnią zmiennej zależnej ze średnią wszystkich kolejnych poziomów kolumny kategorialnej, drugi kontrast porównuje średnią zmienna zależna ze średnią wszystkich kolejnych poziomów, itd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Część II***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treść\n",
    "\n",
    "W tej części zadania traktujemy zmienną price nie jak target a zmienną objaśniającą. Zbiór danych ograniczamy do zmiennych numerycznych tj. price, it_seller_rating i it_quantity.\n",
    "\n",
    "Proszę losowo usunąć 10% wartości ze zmiennej it_seller_rating i je uzupełnić z użyciem jednego z automatycznych narzędzi: Nearest neighbors imputation lub Multivariate feature imputation (https://scikit-learn.org/stable/modules/impute.html).\n",
    "Następnie należy porównać wartości imputowane z oryginalnymi (polecam miarę RMSE). Eksperyment powtórzyć 10 razy i zobaczyć jakie będzie odchylenie standardowe wyniku. Następnie zrobić analogiczną analizę gdy oprócz losowego usuwania 10% wartości z kolumny it_seller_rating usuniemy także losowo 10% ze zmiennej it_quantity. (w przypadku problemów wydajnościowych proszę ograniczyć liczbę rekordów).\n",
    "\n",
    "Opisać wnioski z analizy jakości imputacji i umieścić podsumowujący wykres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pojedyncza iteracja**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw dokonajmy pojedynczej iteracji dla opisanego zadania z usuwaniem danych tylko z jednej kolumny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=transactions_df[['price', 'it_seller_rating', 'it_quantity']]\n",
    "df2=df.copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df.sample(frac=0.1).index, 'it_seller_rating'] = np.nan\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do imputacji brakujących zmiennych używam IterativeImputera (Multivariate feature imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(random_state=0, skip_complete=True, n_nearest_features=10)\n",
    "df3=imp.fit_transform(df2)\n",
    "df3=pd.DataFrame(df3, columns=['price','it_seller_rating','it_quantity'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputer zadziałał, gdyż nie mamy brakujących danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.mean_squared_error(df.iloc[:, 1],df3.iloc[:, 1],squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df3, ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 iteracji dla jednej kategorii wybrakowanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=10000, random_state=10, n_nearest_features=100,initial_strategy='mean')\n",
    "v1 = []\n",
    "for i in range(10):\n",
    "    df2=df.copy()\n",
    "    df2.loc[df.sample(frac=0.1).index, 'it_seller_rating'] = np.nan\n",
    "    df3=imp.fit_transform(df2)\n",
    "    df3=pd.DataFrame(df3, columns=['price','it_seller_rating','it_quantity'])\n",
    "    v1.append(sklearn.metrics.mean_squared_error(df.iloc[:, 1],df3.iloc[:, 1], squared=False))\n",
    "    print(\"Mean squared Error : \" + str(sklearn.metrics.mean_squared_error(df.iloc[:, 1],df3.iloc[:, 1], squared=False)))\n",
    "    print('Standard deviation for all variables:')\n",
    "    print(np.std(df3, ddof=0))\n",
    "    print(\" \")\n",
    "std1 = np.std(v1, axis=0)\n",
    "print('Standard deviation for RMSE: '+str(std1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 iteracji dla dwóch kategorii wybrakowanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=10000, random_state=10, n_nearest_features=100,initial_strategy='mean')\n",
    "v2 = []\n",
    "v3 = []\n",
    "for i in range(10):\n",
    "    df2=df.copy()\n",
    "    df2.loc[df.sample(frac=0.1).index, 'it_seller_rating'] = np.nan\n",
    "    df2.loc[df.sample(frac=0.1).index, 'it_quantity'] = np.nan\n",
    "    df3=imp.fit_transform(df2)\n",
    "    df3=pd.DataFrame(df3, columns=['price','it_seller_rating','it_quantity'])\n",
    "    v2.append(sklearn.metrics.mean_squared_error(df.iloc[:, 1],df3.iloc[:, 1], squared=False))\n",
    "    v3.append(sklearn.metrics.mean_squared_error(df.iloc[:, 2],df3.iloc[:, 2], squared=False))\n",
    "    print(\"Mean squared Error it_seller_rating: \" + str(sklearn.metrics.mean_squared_error(df.iloc[:, 1],df3.iloc[:, 1], squared=False)))\n",
    "    print(\"Mean squared Error it_quantity: \" + str(sklearn.metrics.mean_squared_error(df.iloc[:, 2],df3.iloc[:, 2], squared=False)))\n",
    "    print('Standard deviation for all variables:')\n",
    "    print(np.std(df3, ddof=0))\n",
    "    print(\" \")\n",
    "std2 = np.std(v2, axis=0)\n",
    "print('Standard deviation for it_seller_rating RMSE: '+str(std2))\n",
    "std3 = np.std(v3, axis=0)\n",
    "print('Standard deviation for it_quantity RMSE: '+str(std3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wnioski po imputacji:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W obu przypadkach imputacja jest wysoce nieskuteczna, gdyż błąd średniokwadratowy jest duży.\n",
    "\n",
    "Widoczne są też zmiany w wariancjach zmiennych które były uzupełniane.\n",
    "\n",
    "Z drugiej strony stron, w przypadku braków danych, jest to coś z czego faktycznie opłaca się korzystać, gdyż jesteśmy w stanie pozyskać jedynie w małym,stopniu zaburzone rekordy, za to w dużej ilości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera=[1,2,3,4,5,6,7,8,9,10]\n",
    "iters=[0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacje RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "fig, ax = plt.subplots() \n",
    "sns.barplot(itera, y=v1, color='blue', saturation=0.5)\n",
    "ax.set_ylim(11000,12000)\n",
    "plt.title('RMSE for first test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "fig, ax = plt.subplots() \n",
    "sns.barplot(itera, y=v2, color='cyan')\n",
    "ax.set_ylim(11000,12000)\n",
    "plt.title('RMSE for second test, middle column')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "fig, ax = plt.subplots() \n",
    "sns.barplot(itera, y=v3, color='darkblue')\n",
    "ax.set_ylim(7000,7600)\n",
    "plt.title('RMSE for second test, last column')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
