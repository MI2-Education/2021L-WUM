{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceramic-migration",
   "metadata": {},
   "source": [
    "# Praca Domowa 2\n",
    "Bartosz Siński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders import HashingEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_csv(\"./src/allegro-api-transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-method",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trans.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-settlement",
   "metadata": {},
   "source": [
    "# 1.Kodowanie zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-sunset",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trans['it_location'] = TargetEncoder().fit_transform(df_trans['it_location'],df_trans['price'])\n",
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-powder",
   "metadata": {},
   "source": [
    "Przewagą target encoding nad one-hot encoding jest to, że one-hot encoding dla wielu zmiennych kategorycznych może w sposób znaczący zwiększać wymiarowość naszego zbioru danych. Będzie to szczególnie uciążliwe dla zbioru danych zawierających małą liczbę rekordów. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-numbers",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trans_onehot = pd.get_dummies(df_trans,prefix=\"\",prefix_sep=\"\", columns=['main_category'])\n",
    "df_trans_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-opinion",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trans_hashing = HashingEncoder(cols='main_category').fit_transform(df_trans)\n",
    "df_trans_hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-shell",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trans_binary = BinaryEncoder(cols='main_category').fit_transform(df_trans)\n",
    "df_trans_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-investing",
   "metadata": {},
   "source": [
    "One-hot encoding każdej zmiennej kategorycznej przypisuje wartość 1 lub 0, co może spowodowac powstanie wielu nowych kolumn i zwiększenie wymiarowości naszego zbioru danych. Hash Encoder hashuje wartości naszych zmiennych kategorycznych za pomocą zer i jedynek w n-nowych wymiarach. n jest ustawiane przez użytkownika co pozwala na zmniejszego liczby nowo powstałych kolumn.  Jeżeli jednak damy za małe n dla liczby kategorii naszej zmiennej możemy spowodować, że różne kategorie będą miały ten sam klucz hashujący. W binary encoding na początku przekształcamy każdy kategorie na liczbę, a później zapisujemy ją z uzyciem nowych kolumn w formie binarnej. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-million",
   "metadata": {},
   "source": [
    "# 2. Uzupełnienie braków"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-dairy",
   "metadata": {},
   "source": [
    "Do tego ćwiczenia ograniczami liczbę rekordów, ponieważ czasy wykonywania niektórych poleceń były zbyt długie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-momentum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trans_num = df_trans.loc[0:42000,['price','it_seller_rating','it_quantity']]\n",
    "df_trans_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "rows = np.random.randint(42000,size=4200)\n",
    "df_trans_num_nan = df_trans_num.copy()\n",
    "df_trans_num_nan.loc[rows,['it_seller_rating']] = np.nan \n",
    "df_trans_num_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-iceland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trans_num0 = KNNImputer(n_neighbors=2, weights=\"uniform\").fit_transform(df_trans_num_nan)\n",
    "df_trans_num0 = pd.DataFrame(df_trans_num0, columns = ['price','it_seller_rating','it_quantity'])\n",
    "mean_squared_error(df_trans_num[['it_seller_rating']],df_trans_num0[['it_seller_rating']],squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-extraction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(10):\n",
    "    rows = np.random.randint(42000,size=4200)\n",
    "    df_trans_num_nan = df_trans_num.copy()\n",
    "    df_trans_num_nan.loc[rows,['it_seller_rating']] = np.nan \n",
    "    df_trans_numn = KNNImputer(n_neighbors=5, weights=\"uniform\").fit_transform(df_trans_num_nan)\n",
    "    df_trans_numn = pd.DataFrame(df_trans_numn, columns = ['price','it_seller_rating','it_quantity'])\n",
    "    results.append(mean_squared_error(df_trans_num[['it_seller_rating']],df_trans_numn[['it_seller_rating']], squared=False))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-sympathy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results2=[]\n",
    "for i in range(10):\n",
    "    rows = np.random.randint(42000,size=4200)\n",
    "    rows2 = np.random.randint(42000,size=4200)\n",
    "    df_trans_num_nan = df_trans_num.copy()\n",
    "    df_trans_num_nan.loc[rows,['it_seller_rating']] = np.nan \n",
    "    df_trans_num_nan.loc[rows2,['it_quality']] = np.nan \n",
    "    df_trans_numn = KNNImputer(n_neighbors=5, weights=\"uniform\").fit_transform(df_trans_num_nan)\n",
    "    df_trans_numn = pd.DataFrame(df_trans_numn, columns = ['price','it_seller_rating','it_quantity'])\n",
    "    results2.append(mean_squared_error(df_trans_num[['it_seller_rating']],df_trans_numn[['it_seller_rating']],squared=False))\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-strip",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Odchylenie standardowe błędów wartości zmiennej it_seller_rating  dla: jednej zmiennej usuniętej=\"+str(np.std(results))+\", dwóch zmiennych usuniętych=\"+str(np.std(results2)))\n",
    "print(\"Średni błąd RMSE it_seller_rating dla: jednej zmiennej usuniętej=\"+str(np.mean(results))+\", dwóch zmiennych usuniętych=\"+str(np.mean(results2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-garbage",
   "metadata": {},
   "source": [
    "Wartości błędów są rzędu 10^4, czyli taki samo jak wartości it_seller_rating więc wypełnienie luk nie jest dokładne. Może być to spowodowane tym, że szukamy sąsiadów na podstawie tylko dwóch pozostałych zmiennych. Widzimy także na poniższym wykresie, że wartości są rozłożone nierównomiernie co także może powodować wysoki błąd metody najbliższych sąsiadów. Wynik są też dokładniejsze gdy zmienne na podstawie, których wypełniamy braki, także nie posiadają wartości None lub NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-specialist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df_trans_numn,x=\"it_seller_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-pottery",
   "metadata": {},
   "source": [
    "Histogram błędów RMSE dwóch pomiarów, *results1* to eksperymenty gdzie brakowało jednej zmiennej, a *results2* to eksperymenty, gdzie brakowało dwóch zmiennych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame({'results1':results,'results2':results2})\n",
    "df_results= pd.melt(df_results)\n",
    "sns.histplot(data=df_results,x=\"value\",hue=\"variable\",multiple = \"dodge\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
