{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "french-internship",
   "metadata": {},
   "source": [
    "# Praca domowa nr 2\n",
    "#### Bartosz Sawicki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-croatia",
   "metadata": {},
   "source": [
    "## Wczytanie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dropbox.com/s/360xhh2d9lnaek3/allegro-api-transactions.csv?dl=1'\n",
    "\n",
    "input_df = pd.read_csv(url)\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['date'] = pd.to_datetime(input_df.date, format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = input_df.drop(['lp', 'item_id', 'categories', 'date'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-origin",
   "metadata": {},
   "source": [
    "Usuwamy niepotrzebne kolumny.\n",
    "Usuwamy kategorie i datę dla uproszczenia regresji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-production",
   "metadata": {},
   "source": [
    "## Podział na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.drop('price')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[columns], \n",
    "    df['price'], \n",
    "    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-blond",
   "metadata": {},
   "source": [
    "# 1. Kodowanie zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-prototype",
   "metadata": {},
   "source": [
    "## Target encoding `it_location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder(cols=['it_location'])\n",
    "target_encoder.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-collective",
   "metadata": {},
   "source": [
    "##  Kodowanie `main_category`\n",
    "### One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = ce.OneHotEncoder(cols=['main_category'])\n",
    "one_hot = one_hot_encoder.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-walter",
   "metadata": {},
   "source": [
    "One Hot Encoder dla każdej kategorii tworzy nową kolumnę i wstawia do niej 1 gdy obserwacja należy do tej kategorii, 0 w przeciwnym przypadku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-rings",
   "metadata": {},
   "source": [
    "### Hashing Difference Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing_encoder = ce.HashingEncoder(cols=['main_category'])\n",
    "hash_ = hashing_encoder.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-invalid",
   "metadata": {},
   "source": [
    "Hashing encoding działa podobnie jak One Hot, ale przypisuje kategorie do kolumn na podstawie funkcji hashującej, której parametry można ustawić (w szczególności zbiór wartości), więc liczba wynikowych kolumn jest pod kontrolą programisty. Tym kodowaniem możemy kontrolować wymiary zakodowanego zbioru. Gdy ustawimy `n_components`=`len(df.columns)` otrzymamy kodowanie one-hot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-lesbian",
   "metadata": {},
   "source": [
    "### Generalized Linear Mixed Model Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-freeze",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glmm_encoder = ce.GLMMEncoder(cols=['main_category'])\n",
    "glmm = glmm_encoder.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-nothing",
   "metadata": {},
   "source": [
    "Generalized Linear Mixed Model Encoder to samo tuningująca się odmaina Target Encodera. Dla każdej kategorii wylicza regularyzowaną różnicę średniej kategorii od średniej całego zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['glmm', 'hash', 'one-hot']\n",
    "size = [len(x.columns) for x in [glmm, hash_, one_hot]]\n",
    "\n",
    "sns.barplot(x=labels, y=size, color='orange').set_title(\"Size of the transformed data-frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-skating",
   "metadata": {},
   "source": [
    "## Budowa modelu regresji liniowej\n",
    "\n",
    "dla sprawdzenia jak różne kodowanie wpływa na skuteczność\n",
    "\n",
    "### Musimy jeszcze zakodować `seller`\n",
    "\n",
    "Użyjemy target encoder dlatego zmodyfikujemy już istniejący"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder(cols=['it_location', 'seller'])\n",
    "target_encoder.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_one_hot = Pipeline(\n",
    "[\n",
    "    ('transformer_target', target_encoder),\n",
    "    ('transformer_one_hot', one_hot_encoder),\n",
    "    ('linear-model', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe_backward = Pipeline(\n",
    "[\n",
    "    ('transformer_target', target_encoder),\n",
    "    ('transformer_hashing', hashing_encoder),\n",
    "    ('linear-model', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe_glmm = Pipeline(\n",
    "[\n",
    "    ('transformer_target', target_encoder),\n",
    "    ('transformer_glmm', glmm_encoder),\n",
    "    ('linear-model', LinearRegression())\n",
    "])\n",
    "\n",
    "pipes = [pipe_backward, pipe_glmm, pipe_one_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipe in pipes:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(f' {pipe.steps[1][0]} RMSE : {np.sqrt(mean_squared_error(y_test, y_pred)):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-conjunction",
   "metadata": {},
   "source": [
    "W tym przypadku najlepsze okazało się kodowanie one-hot, najgorsze natomiast kodowanie hashujące."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-impression",
   "metadata": {},
   "source": [
    "# 2. Uzupełnianie braków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-tracy",
   "metadata": {},
   "source": [
    "Aby skrócić czas obliczeń ograniczylem zbiór danych do 1000 obserwacji.\n",
    "\n",
    "Poniżej dla `i`=1,...10 wykonano 10 razy imputację z parametrem `n_neighbors`=`i` z jedną brakującą kolumną (`it_seller_rating`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}\n",
    "\n",
    "def remove_and_impute(n_neighbors):\n",
    "    df2 = input_df[['price', 'it_seller_rating', 'it_quantity']].sample(1000, random_state=997).copy(deep=True).reset_index()\n",
    "    \n",
    "    removed = df2['it_seller_rating'].sample(frac=.1)\n",
    "    df2.loc[removed.index,'it_seller_rating'] = np.nan\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, weights=\"uniform\")\n",
    "    imputed = imputer.fit_transform(df2)\n",
    "    \n",
    "    if errors.get(n_neighbors-1) is None:\n",
    "        errors.update({n_neighbors-1 :[]})\n",
    "    errors.get(n_neighbors-1).append(np.sqrt(mean_squared_error(imputed[removed.index,2], removed)))\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        remove_and_impute(i+1)\n",
    "        \n",
    "errors_df = pd.DataFrame(errors) # cols = n_neighbors-1\n",
    "std1 = errors_df.describe().loc['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-africa",
   "metadata": {},
   "source": [
    "Następnie usunięto 2 kolumny (`it_seller_rating`, `it_location`) i powtórzono wcześniejszą procedurę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_2 = {}\n",
    "\n",
    "def remove_and_impute(n_neighbors):\n",
    "    df2 = input_df[['price', 'it_seller_rating', 'it_quantity']].sample(1000, random_state=997).copy(deep=True).reset_index()\n",
    "    \n",
    "    removed = df2.sample(frac=.1)\n",
    "    df2.loc[removed.index,['it_seller_rating', 'it_location']] = np.nan\n",
    "     \n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, weights=\"uniform\")\n",
    "    imputed = imputer.fit_transform(df2)\n",
    "    \n",
    "    if errors_2.get(n_neighbors-1) is None:\n",
    "        errors_2.update({n_neighbors-1 :[]})\n",
    "    errors_2.get(n_neighbors-1).append(np.sqrt(mean_squared_error(imputed[removed.index,2], removed['it_seller_rating'])))\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        remove_and_impute(i+1)\n",
    "\n",
    "\n",
    "errors_2df = pd.DataFrame(errors_2)\n",
    "std2 = errors_2df.describe().loc['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(15,5))\n",
    "fig.suptitle('Porównanie imputacji KNN przy jednej i dwóch brakujących zmiennych')\n",
    "axes[0].set_title('Brakuje `it_seller_rating`')\n",
    "axes[1].set_title('Brakuje `it_seller_rating` oraz `it_location`')\n",
    "\n",
    "ax = sns.boxplot(ax = axes[0], data = errors_df)\n",
    "ax.set_xticklabels(labels = [i+1 for i in range(len(errors_df.columns))])\n",
    "ax.set_xlabel('n_neighbors')\n",
    "ax.set_ylabel('RMSE (imputed vs real values)')\n",
    "\n",
    "\n",
    "ax3 = sns.boxplot(ax = axes[1], data = errors_2df)\n",
    "ax3.set_xticklabels(labels = [i+1 for i in range(len(errors_2df.columns))])\n",
    "ax3.set_xlabel('n_neighbors')\n",
    "ax3.set_ylabel('RMSE (imputed vs real values)')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(15,5))\n",
    "fig.suptitle('Średnia i odchylenie standardowe RMSE imputacji w 10 próbach')\n",
    "ax2 = sns.lineplot(ax=axes[0], data = pd.melt(errors_df),x = pd.melt(errors_df)['variable']+1, y = 'value', ci='sd')\n",
    "ax4 = sns.lineplot(ax=axes[1], data = pd.melt(errors_2df),x = pd.melt(errors_df)['variable']+1, y = 'value', ci='sd')\n",
    "ax2.set_xlabel('n_neighbors')\n",
    "ax4.set_xlabel('n_neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-superior",
   "metadata": {},
   "source": [
    "Wyniki imputacji są podobne, niezależnie od tego czy opieramy się na jednej czy na dwóch kolumnach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
