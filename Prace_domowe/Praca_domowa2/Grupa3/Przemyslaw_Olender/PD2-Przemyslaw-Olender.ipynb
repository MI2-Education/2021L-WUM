{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from category_encoders import TargetEncoder, OneHotEncoder, CountEncoder, OrdinalEncoder\n",
    "import random\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro = pd.read_csv('allegro-api-transactions.csv')\n",
    "\n",
    "allegro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-executive",
   "metadata": {},
   "source": [
    "## Zadanie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-council",
   "metadata": {},
   "source": [
    "Wykonaj target encoding dla zmiennej it_location. Czy i jakie są przewagi target encoding nad one-hot? Jako target traktujemy kolumnę price (będzie to więc zadanie regresji).\n",
    "\n",
    "Zastosuj trzy metody encodingu (one-hot + \"dwie nowe\") dla kolumny main_category. \"Nowe metody\" proszę wybrać spośród wymienionych na stronie https://contrib.scikit-learn.org/category_encoders/. W przypadku, gdy użyta metoda nie działa proszę o stosowną adnotację. Opisz wyniki.\n",
    "\n",
    "Zwizalizuj wynik oraz wyjaśnij czym się różnią sposoby kodowania (czemu to działa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = allegro[['it_location']].groupby(['it_location']).size().sort_values(ascending=False).reset_index()\n",
    "location.columns = ['location', 'count']\n",
    "\n",
    "location.loc[location['location'].apply(lambda x:'warszawa' in x.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-nation",
   "metadata": {},
   "source": [
    "Warszawa, WARSZAWA i warszawa to zupełnie to samo, można ujednolicić, trzeba się zastanowić nad innymi nazwami. \n",
    "\n",
    "Tak samo jest z innymi miastami, żeby ujednolicić najłatwiej przekształcić wszystkie nazwy tak, żeby skłądały się tylko z małych liter, nie będzie wtedy problemu z wieloczłonowymi nazwami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro['it_location'] = allegro['it_location'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro['it_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = TargetEncoder()\n",
    "\n",
    "allegro['target_encoding_location'] =  target_encoder.fit_transform(allegro['it_location'], allegro['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-diagram",
   "metadata": {},
   "source": [
    "Pojawiła się nowa kolumna - 'target_encoding_location', zakodowana wartość to średnia z wartośći kolumny 'price', dla danej wartości 'it_location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    OneHotEncoder(use_cat_names=True, cols = ['it_location']).fit_transform(allegro.it_location)\n",
    "except MemoryError as error:\n",
    "    print('Brakuje pamieci, ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-financing",
   "metadata": {},
   "source": [
    "OneHotEncoding potrzbuje dużo dodatkowej pamięci do zakodowania zmiennej 'it_location', chcąc dołączyć zakodowaną macierz do ramki danych potrzebował by jeszcze znacznie więcej zasobów - to spory minus, kolejna pamięć byłaby potrzeba na wykonywanie operacji na nowo powstałej ramce. \n",
    "\n",
    "W tym przypadku TargetEncoder sprawdza się znacznie lepiej, lecz on też ma swoje wady. Kodując za pomocą średniej stwarza możliwość porównywania zakodowanych wartości, co może być mylące."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-moore",
   "metadata": {},
   "source": [
    "### OneHotEncoder\n",
    "\n",
    "Kodowanie kolumny 'main_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotEncoder(cols = ['main_category'], use_cat_names=True).fit_transform(allegro.main_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-somalia",
   "metadata": {},
   "source": [
    "### CountEncoder\n",
    "\n",
    "Każdej wartości z kolumny 'main_categoty' przyporządkowuje liczbę jej wystąpień."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountEncoder(cols=['main_category']).fit_transform(allegro.main_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-kentucky",
   "metadata": {},
   "source": [
    "### OrdinalEncoder\n",
    "\n",
    "Tworzy kolumne intów, każdej unikatowj wartości z 'main_category' przyporządkowuje kolejną wartość naturalną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "OrdinalEncoder(cols=['main_category']).fit_transform(allegro.main_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-malawi",
   "metadata": {},
   "source": [
    "Tak jak poprzednio, OneHotEncoding potrzebuje najwięcej pamięci i dodaje do ramki 27 nowych kolumn. CountEncoder i OrdinalEncoder zachowują się podobnie do TargetEncoder, Count zamiast średniej liczy liczbę wystąpień, da się porównywać zakodowane zmienne, co nie jest dobrą cechą. Ordinal dopasowuje kolejno dobrane liczby naturalne, co za tym idzie nie mają one nic wspólengo z kodowaną zmienną, również da się je porównywać."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-staff",
   "metadata": {},
   "source": [
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-yugoslavia",
   "metadata": {},
   "source": [
    "W tej części zadania traktujemy zmienną price nie jak target a zmienną objaśniającą. Zbiór danych ograniczamy do zmiennych numerycznych tj. price, it_seller_rating i it_quantity.\n",
    "\n",
    "Proszę losowo usunąć 10% wartości ze zmiennej it_seller_rating i je uzupełnić z użyciem jednego z automatycznych narzędzi: Nearest neighbors imputation lub Multivariate feature imputation (https://scikit-learn.org/stable/modules/impute.html).\n",
    "Następnie należy porównać wartości imputowane z oryginalnymi (polecam miarę RMSE). Eksperyment powtórzyć 10 razy i zobaczyć jakie będzie odchylenie standardowe wyniku. Następnie zrobić analogiczną analizę gdy oprócz losowego usuwania 10% wartości z kolumny it_seller_rating usuniemy także losowo 10% ze zmiennej it_quantity. (w przypadku problemów wydajnościowych proszę ograniczyć liczbę rekordów).\n",
    "\n",
    "Opisać wnioski z analizy jakości imputacji i umieścić podsumowujący wykres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro_num = allegro[['price', 'it_seller_rating', 'it_quantity']].sample(10000).reset_index(drop = True)\n",
    "\n",
    "#ognaiczyłem dane ze względu na problemy z wydajnością"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allegro_num.shape)\n",
    "allegro_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = allegro_num.sample(int(len(allegro_num) * 0.1)).index\n",
    "\n",
    "lost_data = allegro_num.copy(deep = True)\n",
    "\n",
    "lost_data.loc[indexes,'it_seller_rating'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors = 3,weights = 'uniform').fit_transform(lost_data)\n",
    "\n",
    "filled_data = pd.DataFrame(imputer)\n",
    "\n",
    "filled_data.columns = ['price', 'it_seller_rating', 'it_quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(allegro_num.it_seller_rating, filled_data.it_seller_rating, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "\n",
    "for i in range(10):\n",
    "    indexes = allegro_num.sample(int(len(allegro_num) * 0.1)).index\n",
    "    lost_data = allegro_num.copy(deep = True)\n",
    "    lost_data.loc[indexes,'it_seller_rating'] = np.nan \n",
    "    imputer = KNNImputer(n_neighbors = 3,weights = 'uniform').fit_transform(lost_data)\n",
    "    filled_data = pd.DataFrame(imputer)\n",
    "    filled_data.columns = ['price', 'it_seller_rating', 'it_quantity']\n",
    "    \n",
    "    vals.append(rmse(allegro_num.it_seller_rating, filled_data.it_seller_rating, squared=False))\n",
    "    \n",
    "stdev(vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro_num = allegro_num.sample(5000)\n",
    "#musiałem jeszcze bardziej ograniczyć dane, żeby użyć imputera dla dwóch kolumn\n",
    "\n",
    "vals2 = []\n",
    "\n",
    "for i in range(10):\n",
    "    indexes = allegro_num.sample(int(len(allegro_num) * 0.1)).index\n",
    "    lost_data = allegro_num.copy(deep = True)\n",
    "    lost_data.loc[indexes,'it_seller_rating'] = np.nan \n",
    "    indexes = allegro_num.sample(int(len(allegro_num) * 0.1)).index\n",
    "    lost_data.loc[indexes,'it_quantity'] = np.nan \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors = 3,weights = 'uniform').fit_transform(lost_data)\n",
    "    filled_data = pd.DataFrame(imputer)\n",
    "    filled_data.columns = ['price', 'it_seller_rating', 'it_quantity']\n",
    "    \n",
    "    vals2.append(rmse(allegro_num.it_seller_rating, filled_data.it_seller_rating, squared=False))\n",
    "    \n",
    "stdev(vals2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'missing_cols': np.concatenate([['one_col']*10, ['two_cols']*10]), \n",
    "     'rmse': np.concatenate([vals, vals2])}\n",
    "df = pd.DataFrame(data=dict)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.boxplot(data = df, x = 'missing_cols', y = 'rmse', ax = ax)\n",
    "plt.title('Comprasion for RMSE values for one and two missing columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-plymouth",
   "metadata": {},
   "source": [
    "Wartości RMSE są bardzo duże, czyli imputacja działa słabo. \n",
    "\n",
    "Uzupełnienie brakujących wartości w dwóch kolumnach daje gorsze wyniki niż w jednej."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
