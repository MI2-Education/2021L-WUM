{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pretty-royalty",
   "metadata": {},
   "source": [
    "# Praca Domowa 3\n",
    "Bartosz Siński "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-threshold",
   "metadata": {},
   "source": [
    "### Załadowanie modelu i podział zbioru na treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_aus = pd.read_csv(\"./src/australia.csv\")\n",
    "X= df_aus.drop([\"RainTomorrow\"], axis=1)\n",
    "y = df_aus[\"RainTomorrow\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-finance",
   "metadata": {},
   "source": [
    "### Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-morrison",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lreg = LogisticRegression(random_state=1613,penalty='l1',solver='saga',max_iter=500).fit(X_train, y_train)\n",
    "aus_pred1 = lreg.predict(X_test)\n",
    "accuracy_score(aus_pred1,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-vampire",
   "metadata": {},
   "source": [
    "Dobraliśmy parametry *penalty, max_iter* oraz *solver*. *Penalty* ustawia rodzaj kary, którą nakładamy na model za overfitting. Parametr *Solver* odpowiada za wybór algorytmu opdowiedzialnego za optymalizacje, a *max_iter* za ograniczenie liczby iteracji naszego solvera. Wybraliśmy *saga* ponieważ pozwala on na wybranie parametru regularyzacji L1 i działa szybko na dużych zbiorach danych. Zmiana kary na L1 i zwiększenie liczby iteracji nieznacznie poprawiło accuracy naszego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-impossible",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=1613,kernel = 'linear',C=10)\n",
    "svm.fit(X_train, y_train)\n",
    "aus_pred2 = svm.predict(X_test)\n",
    "accuracy_score(aus_pred2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-freedom",
   "metadata": {},
   "source": [
    "W powyższym modelu SVC ustawiliśmy parametr *kernel*, który ustala typ jądra używanego w algorytmie na liniowy. Zmieniliśmy także parametr regularyzacji *C* z domyślnego 1 na 10. W obu przypadkach zmiana parametru podniosła nasze accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-spectrum",
   "metadata": {},
   "source": [
    "### Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1613,n_estimators = 1000,max_features='log2')\n",
    "rfc.fit(X_train,y_train)\n",
    "aus_pred3 = rfc.predict(X_test)\n",
    "accuracy_score(aus_pred3,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-cincinnati",
   "metadata": {},
   "source": [
    "W modelu Random Forrest zmieniliśmy domyślne wartości parametrów *n_estimators* i *max_features*. *n_estimators* ustala liczbę drzew w naszym lesie na podstawie których będziemy przewidywać wartość targetu. Parametr *max_features* odpowiada za liczbę zmiennych przy podziałach liści. Wartość *n_estimators* podnieśliśmy z 100 do 1000 co zwiększyło czas przygotowania modelu jednak podniosło też jego accuracy. *max_features* zmieniliśmy z domyślnej *sqrt* na *log2* co nie wpłyneło na predykcje naszego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-explosion",
   "metadata": {},
   "source": [
    "### Porównanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-accreditation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "results = {\n",
    "    \"algorithm\" : ['Logistic Regression','SVM','Random Forrest'],\n",
    "    \"accuracy\" : [accuracy_score(y_test,aus_pred1),accuracy_score(y_test,aus_pred2),accuracy_score(y_test,aus_pred3)],\n",
    "    \"precision\" : [precision_score(y_test,aus_pred1),precision_score(y_test,aus_pred2),precision_score(y_test,aus_pred3)],\n",
    "    \"recall\" :[recall_score(y_test,aus_pred1),recall_score(y_test,aus_pred2),recall_score(y_test,aus_pred3)],\n",
    "    'ROC AUC' : [roc_auc_score(y_test,aus_pred1),roc_auc_score(y_test,aus_pred2),roc_auc_score(y_test,aus_pred3)],\n",
    "    'F1' : [f1_score(y_test,aus_pred1),f1_score(y_test,aus_pred2),f1_score(y_test,aus_pred3)]\n",
    "\n",
    "}\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-content",
   "metadata": {},
   "source": [
    "Najlepszym klasyfikatorem okazał się Random Forest. We wszystkich metrykach osiągnął lepszy wynik niż pozstałe modele. Ciekawe wydaje się być, że SVM i Regresja Logistyczna osiągneły bardzo podobne wyniki we wszystkich metrykach.Dodatkowo zaskakujący jest tak wysoki wynik Regresji logistycznej w porównaniu do bardziej zaawansowanych modeli SVM i Random Forrest. Spojrzymy także na *table of confusion* dla tych modeli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-printer",
   "metadata": {},
   "source": [
    "### Regresja Logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, aus_pred1).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-mitchell",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, aus_pred2).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-hazard",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, aus_pred3).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-render",
   "metadata": {},
   "source": [
    "Powyżej widzimy, że Random Forrest najbardziej różni się od pozostałych modeli pod względem zdecydowanie mniejszej liczby predykcji *False Negative*. Widzimy także, że modele o wiele lepiej radzą sobie z klasyfikacją obserwacji, gdzie model przewiduje brak deszczu. Może się to wiązać z dużo większą ilością obserwacji gdzie deszczu nie ma.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
