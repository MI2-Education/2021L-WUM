{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "macro-raise",
   "metadata": {},
   "source": [
    "# Praca Domowa 3\n",
    "Piotr Marciniak\n",
    "## Wczytanie danych i modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compliant-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>1004.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.4</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.4</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56415</th>\n",
       "      <td>19.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56416</th>\n",
       "      <td>21.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56417</th>\n",
       "      <td>20.7</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56418</th>\n",
       "      <td>19.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56419</th>\n",
       "      <td>20.2</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56420 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0         17.9     35.2       0.0         12.0      12.3           48.0   \n",
       "1         18.4     28.9       0.0         14.8      13.0           37.0   \n",
       "2         19.4     37.6       0.0         10.8      10.6           46.0   \n",
       "3         21.9     38.4       0.0         11.4      12.2           31.0   \n",
       "4         24.2     41.0       0.0         11.2       8.4           35.0   \n",
       "...        ...      ...       ...          ...       ...            ...   \n",
       "56415     19.3     33.4       0.0          6.0      11.0           35.0   \n",
       "56416     21.2     32.6       0.0          7.6       8.6           37.0   \n",
       "56417     20.7     32.8       0.0          5.6      11.0           33.0   \n",
       "56418     19.5     31.8       0.0          6.2      10.6           26.0   \n",
       "56419     20.2     31.7       0.0          5.6      10.7           30.0   \n",
       "\n",
       "       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
       "0               6.0          20.0         20.0         13.0       1006.3   \n",
       "1              19.0          19.0         30.0          8.0       1012.9   \n",
       "2              30.0          15.0         42.0         22.0       1012.3   \n",
       "3               6.0           6.0         37.0         22.0       1012.7   \n",
       "4              17.0          13.0         19.0         15.0       1010.7   \n",
       "...             ...           ...          ...          ...          ...   \n",
       "56415           9.0          20.0         63.0         32.0       1013.9   \n",
       "56416          13.0          11.0         56.0         28.0       1014.6   \n",
       "56417          17.0          11.0         46.0         23.0       1015.3   \n",
       "56418           9.0          17.0         62.0         58.0       1014.9   \n",
       "56419          15.0           7.0         73.0         32.0       1013.9   \n",
       "\n",
       "       Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0           1004.4       2.0       5.0     26.6     33.4          0   \n",
       "1           1012.1       1.0       1.0     20.3     27.0          0   \n",
       "2           1009.2       1.0       6.0     28.7     34.9          0   \n",
       "3           1009.1       1.0       5.0     29.1     35.6          0   \n",
       "4           1007.4       1.0       6.0     33.6     37.6          0   \n",
       "...            ...       ...       ...      ...      ...        ...   \n",
       "56415       1010.5       0.0       1.0     24.5     32.3          0   \n",
       "56416       1011.2       7.0       0.0     24.8     32.0          0   \n",
       "56417       1011.8       0.0       0.0     24.8     32.1          0   \n",
       "56418       1010.7       1.0       1.0     24.8     29.2          0   \n",
       "56419       1009.7       6.0       5.0     25.4     31.0          0   \n",
       "\n",
       "       RainTomorrow  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "56415             0  \n",
       "56416             0  \n",
       "56417             0  \n",
       "56418             0  \n",
       "56419             0  \n",
       "\n",
       "[56420 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weather_df = pd.read_csv('../../australia.csv')\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-support",
   "metadata": {},
   "source": [
    "## Podział na zbiór treningowy i testowy\n",
    "Jako, że mamy dużo danych zastosujemy podział 60%-40% danych treningowych do danych testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greater-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = weather_df.drop(columns=\"RainTomorrow\")\n",
    "y = weather_df[\"RainTomorrow\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-tension",
   "metadata": {},
   "source": [
    "## Nauka klasyfikatorów\n",
    "\n",
    "### Random Forest\n",
    "Oprócz hiperparametrów poznanych na ostatnich laboratoriach zainteresował mnie parametr **max_leaf_nodes**, która określa nam maksymalną ilość liści, czyli de facto trafień do dodanych grup. Może powodować powstawanie dużo podziałów, które zachodzą dla tylko zbioru treningowego. Powinien być przydatny w razie overfittingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loose-privacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, max_features=4, max_leaf_nodes=13,\n",
       "                       min_samples_split=3, n_estimators=500, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "                            n_estimators=500, \n",
    "                            max_depth=4, \n",
    "                            min_samples_split=3,\n",
    "                            max_features=4, \n",
    "                            max_leaf_nodes=13,\n",
    "                            random_state=42,\n",
    "                            n_jobs = -1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enhanced-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)\n",
    "rfc_prob = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-baker",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Oprócz hiperparametrów poznanych na ostatnich laboratoriach zainteresował mnie parametr **subsample**. Mówi nam o stosunku przykładów treningowych użytych w danej boostingowej iteracji. Defaultowo jest on ustawiony na 1, czyli cały zbiór treningowy jest użyty w jednej iteracji. Ustawione tej wartości na 0.5, spowoduje losowe podzielenie zbioru na połowę. Wskazujemy frakcję naszego zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latest-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.0001,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.8, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.0001,\n",
    "                    booster='gbtree', \n",
    "                    max_depth=6,\n",
    "                    eval_metric=\"logloss\", \n",
    "                    random_state=42,\n",
    "                    subsample=0.8,\n",
    "                    use_label_encoder=False #nie używamy enkodera sklearn'a\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specific-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_prob = xgb.predict_proba(X_test)\n",
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-mortality",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine\n",
    "Hiperparametrem, na którym się skupimy jest **kernel**, czyli funkcje według dokonujemy podziału. Możemy wybrać już z przygotowanych czyli \n",
    "* linear - liniowe,\n",
    "* poly - wielomianowe,\n",
    "* rbf - radial basis function jest to rodzina funkcji, w przypadku domyślnego sci-kita mamy $\\exp\\left(-\\gamma\\|x-x'\\|^2\\right)$, \n",
    "* sigmoid - $\\tanh\\left(\\lambda x^T y + c\\right)$,\n",
    "* precomputed - możemy podać własną funkcję jądra.\n",
    "\n",
    "Z powodu dużej ilości danych użycie Gaussowskiego jądra jest kosztowne, dlatego użyjemy wielomianowe stopnia 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ethical-yellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(cache_size=1000, degree=2, kernel='poly', probability=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "svc = SVC(kernel='poly', degree=2, cache_size=1000, probability=True) \n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freelance-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_prob = svc.predict_proba(X_test)\n",
    "svc_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-employer",
   "metadata": {},
   "source": [
    "## Porównanie klasyfikatorów\n",
    "Do wstępnego porównania użyjemy na początek *accuracy*. Później spojrzymy na macierz pomyłek (*confusion matrix*). W zależności od tego, jak zdefinujemy nasz problem możemy chcieć wysoki *recall* (farmerzy, których interesuje, jak przewidujemy opad deszczu, aby zaplanować koszenie traw) lub *specifity* (turyści, którym zależy na słonecznej pogodzie), dlatego użyjemy również *ROC curve*, czyli zależności od *recallu* od *specifity* może pomóc dobrać threshold.\n",
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radical-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.843274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.838843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0           Random Forest  0.843274\n",
       "1                 XGBoost  0.846154\n",
       "2  Support Vector Machine  0.838843"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pd.DataFrame([\n",
    "            (\"Random Forest\", accuracy_score(y_true=y_test, y_pred=rfc_pred)),\n",
    "            (\"XGBoost\", accuracy_score(y_true=y_test, y_pred=xgb_pred)),\n",
    "            (\"Support Vector Machine\", accuracy_score(y_true=y_test, y_pred=svc_pred)),\n",
    "            ], \n",
    "            columns=[\"Model\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-administration",
   "metadata": {},
   "source": [
    "Jak widzimy accuracy średnio rozróżnia nam nasze klasyfikatory (najlepsze różnią się na 3 cyfrze znaczącej)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-crawford",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generous-going",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "def plot_confusion_matrix(ax, y_true, y_pred, name):\n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(C, annot=True, ax=ax, cmap='Blues', cbar=False, fmt=\"d\")\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "\n",
    "plot_confusion_matrix(axes[0], y_test, rfc_pred, \"Random Forest\")\n",
    "plot_confusion_matrix(axes[1], y_test, xgb_pred, \"XGBoost\")\n",
    "plot_confusion_matrix(axes[2], y_test, svc_pred, \"Support Vector Machine\")\n",
    "axes[0].set_ylabel(\"True label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-perspective",
   "metadata": {},
   "source": [
    "Widzimy, że *XGBoost* ma najniższy recall, zatem jego zalecałbym dla farmerów, natomiast *specifity* ma najniższy SVM zatem jego zaleciłbym chcącym opalić się turystom. Zatem spójrzmy na poniższą ramkę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "impressive-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.402920</td>\n",
       "      <td>0.799843</td>\n",
       "      <td>0.535888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.478887</td>\n",
       "      <td>0.744936</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.356551</td>\n",
       "      <td>0.827760</td>\n",
       "      <td>0.498414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model    Recall  Precision  F1-score\n",
       "0           Random Forest  0.402920   0.799843  0.535888\n",
       "1                 XGBoost  0.478887   0.744936  0.582993\n",
       "2  Support Vector Machine  0.356551   0.827760  0.498414"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "pd.DataFrame([\n",
    "            (\"Random Forest\", recall_score(y_true=y_test, y_pred=rfc_pred), precision_score(y_true=y_test, y_pred=rfc_pred), f1_score(y_true=y_test, y_pred=rfc_pred)),\n",
    "            (\"XGBoost\", recall_score(y_true=y_test, y_pred=xgb_pred), precision_score(y_true=y_test, y_pred=xgb_pred), f1_score(y_true=y_test, y_pred=xgb_pred)),\n",
    "            (\"Support Vector Machine\", recall_score(y_true=y_test, y_pred=svc_pred), precision_score(y_true=y_test, y_pred=svc_pred), f1_score(y_true=y_test, y_pred=svc_pred)),\n",
    "            ], \n",
    "            columns=[\"Model\", \"Recall\", \"Precision\", \"F1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-encyclopedia",
   "metadata": {},
   "source": [
    "Z F1 widzimy, że n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-correspondence",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred, name):\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plot_roc_curve(y_test, rfc_prob[:, 1], \"Random Forest\")\n",
    "plot_roc_curve(y_test, xgb_prob[:, 1], \"XGBoost\")\n",
    "plot_roc_curve(y_test, svc_prob[:, 1], \"Support Vector Machine\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-atlanta",
   "metadata": {},
   "source": [
    "Jaki widzimy XGBoost ma najlepszą krzywą (najbliższą do idealnej)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-basement",
   "metadata": {},
   "source": [
    "## Wniosek\n",
    "Najlepsze wyniki osiągnał XGBoost, wynika to właściwe ze wszystkich użytych metryk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}