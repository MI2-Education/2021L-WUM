{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vulnerable-accreditation",
   "metadata": {},
   "source": [
    "# Zadanie Domowe 3 - Katarzyna Solawa\n",
    "Zbiór danych zawiera codzienne obserwacje pogody z wielu australijskich stacji pogodowych. Waszym zadaniem będzie stworzenie modelu klasyfikacyjnego, który będzie potrafił przewidzieć czy następnego dnia będzie padał deszcz czy też nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-journalist",
   "metadata": {},
   "source": [
    "## Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"australia.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-example",
   "metadata": {},
   "source": [
    "## Podział danych na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['RainTomorrow'])\n",
    "X = df.drop(['RainTomorrow'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-plaza",
   "metadata": {},
   "source": [
    "## Nauczenie 3 dowolnych klasyfikatorów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-thumb",
   "metadata": {},
   "source": [
    "## W każdym klasyfikatorze należy wybrać minimum jeden hiperparametr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='sigmoid')\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "y_hat_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-franklin",
   "metadata": {},
   "source": [
    "`kernel` - domyślnie 'rbf', możliwe do wyboru: 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=5000, solver='sag')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat_logreg = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-reflection",
   "metadata": {},
   "source": [
    "`solver` - Algorytm wykorzystywany w problemie optymalizacji , domyślnie równy 'lbfgs'\n",
    "\n",
    "'sag' wspiera `penalty` = 'l2', co jest ustawieniem domyślnym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree #export_graphviz\n",
    "## biblioteka poniżej może być problematyczna na Windows\n",
    "#import graphviz\n",
    "\n",
    "tree1 = DecisionTreeClassifier(splitter='random')\n",
    "\n",
    "tree1.fit(X_train,y_train)\n",
    "y_hat_tree = tree1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-sandwich",
   "metadata": {},
   "source": [
    "`splitter` -Strategia użyta do wyboru podziału w każdym węźle, domyślnie ma wartość 'best'.\n",
    "\n",
    "`splitter`='random' wybiera najlepszy losowy podział"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-enemy",
   "metadata": {},
   "source": [
    "## Wykorzystanie przynajmniej 3 miar oceny jakości klasyfikatorów i wybór najlepszego z nich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test,y_hat_svm))\n",
    "print(accuracy_score(y_test, y_hat_svm))\n",
    "print(precision_score(y_test, y_hat_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test,y_hat_logreg))\n",
    "print(accuracy_score(y_test, y_hat_logreg))\n",
    "print(precision_score(y_test, y_hat_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test,y_hat_tree))\n",
    "print(accuracy_score(y_test, y_hat_tree))\n",
    "print(precision_score(y_test, y_hat_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-porter",
   "metadata": {},
   "source": [
    "Dla trzech klasyfiktaorów najwyższą miarę jakości otrzymaliśmy dla `Accuracy`. Najbardziej rozbierzne wyniki otrzymaliśmy dla klasyfikatora `SVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_m = confusion_matrix(y_test, y_hat_svm)\n",
    "pd.DataFrame(conf_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-chambers",
   "metadata": {},
   "source": [
    "TN = 10979\n",
    "\n",
    "FN = 3123\n",
    "\n",
    "TP = 3\n",
    "\n",
    "FP = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-copying",
   "metadata": {},
   "source": [
    "`Accuracy` mówi nam ile było poprawnych wyników w stosunku do całości, a `F1 score` głównie zwraca uwagę na TP, które w naszym przypadku jest małe. W naszych danych więszość wyników stanowi TN. Gdyby jako wynik pozytywny przyjąć brak deszczu następnego dnia, wtedy zarówno dla `Accuracy` oraz `F1 score`, otrzymamy wysoką miarę jakości. Podobnie dla `Precision` które sprawdza stosunek TP do sumy TP i FP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_m = confusion_matrix(y_test, y_hat_logreg)\n",
    "pd.DataFrame(conf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_m = confusion_matrix(y_test, y_hat_tree)\n",
    "pd.DataFrame(conf_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-posting",
   "metadata": {},
   "source": [
    "`Accuracy` jezt zbyt ogólną miarą jakości, skupia się tylko na poprawnych wynikach. Jeżeli bardziej interesuje nas sprawdzenie jakości dla TP albo TN(wtedy trzeba zaminić wyniki negatywne z pozytywnymi), wiecej dowiemy się używając w odpowiedni sposób `F1 score` lub `Precision`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-bosnia",
   "metadata": {},
   "source": [
    "W zadaniu przewidzenia czy bedzię padać nastęnego dnia, wydaje mi się, że predykcja wystąpienia deszczu jest ważniejsza. Dlatego uważam, że najlepszą miarą bedzie `F1-score`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
