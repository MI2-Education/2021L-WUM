{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD3 - Jan Smoleń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import category_encoders as ce\n",
    "import sklearn.metrics as metrics\n",
    "import statistics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"australia.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu przyśpieszeniea późniejszego tuningowania hiperparametrów ograniczę liczbę rekordów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop([\"RainTomorrow\"], axis=1)\n",
    "y=df[\"RainTomorrow\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Pierwszym testowanym przez nas modelem będzie SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_base=SVC(random_state=42)\n",
    "svm_base.fit(X_train, y_train)\n",
    "preds=svm_base.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy, SVM z domyślnymi hiperparametrami osiąga accuracy score powyżej 77%. Spróbujemy teraz znaleźć dobrą kombinacje hiperparametrów gamma i C korzystając z narzędzia GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tuned=SVC(random_state=42)\n",
    "c=[]  # wartości parametru C\n",
    "gamma=[]  #wartości parametru gamma \n",
    "for i in range(-4, 5):      # orientacyjne wartości na podstawie informacji znalezionych w internecie\n",
    "    c.append(10**i)\n",
    "for i in range(-4, 5):\n",
    "    gamma.append(10**i)\n",
    "gamma.append(\"auto\")\n",
    "gamma.append(\"scale\")\n",
    "params = [{'C': c,   \n",
    "        'gamma': gamma}]\n",
    "gs_svm=GridSearchCV(svm_tuned, param_grid=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "gs_svm.fit(X_train, y_train)\n",
    "gs_svm.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc=accuracy_score(gs_svm.predict(X_test),y_test)\n",
    "svm_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning dwóch hiperparametrów pozwala zatem na poprawienie accuracy score modelu o prawie 10% przy wartościach C=100, gamma=0.0001. Gdyby celem zadania było znalezienie optymalnych parametrów to moglibyśmy poszukać także w okolicach tych wartości oraz zmodyfikować atrybut kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(objective = \"binary:logistic\", seed = 1613, use_label_encoder=False)\n",
    "xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(xgb_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surowy XGBoost daje znacznie lepszy wynik accuracy score niż SVM z domyślnymi parametrami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned=xgb.XGBClassifier(objective = \"binary:logistic\", seed = 1613, use_label_encoder=False)\n",
    "eta=[]  #wartości parametru eta \n",
    "max_depth=[]\n",
    "for i in range(10):\n",
    "    eta.append(0.01+0.03) \n",
    "    max_depth.append(i)\n",
    "params = [{'eta': eta,\n",
    "        'max_depth': max_depth}]\n",
    "gs_xgb=GridSearchCV(xgb_tuned, param_grid=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "gs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_acc=accuracy_score(gs_xgb.predict(X_test), y_test)\n",
    "xgb_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym przypadku nie udało się polepszyć wyników modelu poprzez tuning hiperparametrów max_depth i eta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=16)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(rfc.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czyli takie same accuracy jak używając XGBoosta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tuned=RandomForestClassifier(random_state=16)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 1000, num = 5)] # przykładowe wartości znalezione w internecie \n",
    "max_depth = [int(x) for x in np.linspace(5, 55, num = 5)]\n",
    "             \n",
    "params = [{'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth}]\n",
    "gs_rfc=GridSearchCV(rfc_tuned, param_grid=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "gs_rfc.fit(X_train, y_train)\n",
    "gs_rfc.best_params_             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_acc=accuracy_score(gs_rfc.predict(X_test),y_test)\n",
    "rfc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czyli udało się trochę polepszyć wynik naszego modelu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocena jakości modeli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "labels=[]\n",
    "scores.append(svm_acc)\n",
    "labels.append(\"SVM\")\n",
    "scores.append(xgb_acc)\n",
    "labels.append(\"XGB\")\n",
    "scores.append(rfc_acc)\n",
    "labels.append(\"RFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Accuracy Score\": scores}, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs_svm.predict(X_test)).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs_xgb.predict(X_test)).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, gs_rfc.predict(X_test)).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svm\n",
    "plt.figure(figsize=(12,10))\n",
    "classifiers = [gs_svm, gs_xgb, gs_rfc]\n",
    "labels=[\"SVM\", \"XGB\", \"RFC\"]\n",
    "ax = plt.gca()\n",
    "for i in range(3):\n",
    "    metrics.plot_roc_curve(classifiers[i], X_test, y_test, ax=ax, name=labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biorąc pod uwagę powyższe oceny jakości klasyfikatorów, w tym konkretnym przypadku najlepszym z nich wydaje się **SVM** z wytuningowanymi hiperparametrami C i gamma. Być może inne wyniki byśmy otrzymali przeprowadzając wcześniej feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
