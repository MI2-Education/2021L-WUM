{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score,  f1_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Rzeczywiście nie ma nulli w bazie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od podzielenia ramki danych względem taretu(*RainTomorrow*) i poszukajmy jakichś zależności między nimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.RainTomorrow==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.RainTomorrow==0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na pierwszy rzut oka najważniejszymi zmiennymi będą zachmurzenie, wilgotność oraz opady w dniu dzisiejszym, co raczej nikogo nie zdziwi. Co ciekawe ciśnienie spada, a pędkość wiatru rośnie w dni deszczowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=30,figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['RainTomorrow'],axis=1)\n",
    "y=df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaczniemy od regresji logistycznej z prametrami:\n",
    "   - penalty=l2, ponieważ chcemy aby model był zależny od jak najmniejszej liczby parametrów,\n",
    "   - dual=False, ponieważ n_samples>n_features, \n",
    "   - n_jobs=-1, ponieważ jeśli coś da się zrobić szybciej to nie ma co się oganiczać,\n",
    "   - class_weight=balanced, ponieważ dni bez opadów jest sporo więcej, więc chcemy trochę bardziej to zrównoważyć tą dysproporcję."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(penalty='l2',dual=False,n_jobs=-1,max_iter=1500,random_state=72,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accurancy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"recall score: {recall_score(y_test,y_pred)}\")\n",
    "print(f\"f1 score: {f1_score(y_test,y_pred)}\")\n",
    "print(f\"precision score: {precision_score(y_test,y_pred)}\")\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie sprawdzimy Las losowy z prametrami:\n",
    "   - n_estimators=100,\n",
    "   - min_samples_leaf=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=RandomForestClassifier( n_estimators=100, random_state=10, min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(x_train,y_train)\n",
    "y_pred3=model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accurancy: {accuracy_score(y_test,y_pred3)}\")\n",
    "print(f\"recall score: {recall_score(y_test,y_pred3)}\")\n",
    "print(f\"f1 score: {f1_score(y_test,y_pred3)}\")\n",
    "print(f\"precision score: {precision_score(y_test,y_pred3)}\")\n",
    "confusion_matrix(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec sprawdzimy VotingClassifier z prametrami:\n",
    "   - estimators=[('LR',model),('RFC',model3)], ponieważ chcemy sprawdzić, czy Random Forest połączony z Regresją liniową dadzą wspólnie lepszy efekt,\n",
    "   - voting='soft', \n",
    "   - n_jobs=-1, ponieważ  jeśli coś da się zrobić szybciej to nie ma co się oganiczać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=VotingClassifier( estimators=[('LR',model),('RFC',model3)], voting='soft',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x_train,y_train)\n",
    "y_pred2=model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accurancy: {accuracy_score(y_test,y_pred2)}\")\n",
    "print(f\"recall score: {recall_score(y_test,y_pred2)}\")\n",
    "print(f\"f1 score: {f1_score(y_test,y_pred2)}\")\n",
    "print(f\"precision score: {precision_score(y_test,y_pred2)}\")\n",
    "confusion_matrix(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybranie najlepszego modelu jest dość subiektywne ze względu na subiektywność, która metryka jest najlepsza dla danego zadania. Jeśli patrzymy na f1 to wygrywa VotingClassifier, najlepsze accurancy osiąga Random Forest, w recall zwycięża regresja logistyczna, a w precision score Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
