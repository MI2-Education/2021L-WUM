{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pobranie danych\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mini-pw/2021L-WUM/main/Prace_domowe/Praca_domowa3/australia.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12,16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-sister",
   "metadata": {},
   "source": [
    "Dla pewności sprawdziłem rozkłady wszystkich zmiennych. Wydają się wyglądać w porządku, bez żadnych wyraźnych anomalii. Dodatkowo widać tu, że zmienna celu nie jest zbalansowana - mamy więcej zer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"RainTomorrow\", axis=1)\n",
    "y = df[[\"RainTomorrow\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-royalty",
   "metadata": {},
   "source": [
    "Żeby sprawdzić, czy `X` i `y` dobrze się przycięły można wyświetlić kilka pierwszych wierszy i sprawdzić, czy ramki mają odpowiedni kształt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-drinking",
   "metadata": {},
   "source": [
    "Widać tutaj, że zbiór danych jest raczej przekrzywiony w stronę zera - mamy dysproporcję klas. Więcej wierszy pochodzi z dni, gdy nie padał deszcz. Wypada użyć argumentu `stratify` przy podziale, aby zachować odpowiednie proporcje klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-castle",
   "metadata": {},
   "source": [
    "Pierwszym modelem, z którego skorzystam jest regresja logistyczna. W tym przypadku ustawiłem następujące hiperparametry:\n",
    "- `penalty = \"l2\"` - ustawienie regularyzacji na l2\n",
    "- `C = 1.2` - ustawienie wagi regularyzacji na trochę łagodniejszą niż domyślna\n",
    "- `max_iter = 1000` - zwiększenie domyślnej maksymalnej liczby iteracji tego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(penalty=\"l2\", C=1.2, max_iter=1000, random_state=42)\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "logit_pred = logit.predict(X_test)\n",
    "\n",
    "acc_logit = accuracy_score(y_test, logit_pred)\n",
    "rec_logit = recall_score(y_test, logit_pred)\n",
    "f1_logit = f1_score(y_test, logit_pred)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\".format(acc_logit, rec_logit, f1_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-collection",
   "metadata": {},
   "source": [
    "Kolejnym modelem jest las losowy. Parametry, które tu ustawiłem to:\n",
    "- `n_estimators=20` - liczba drzew, z których korzysta ten klasyfikator\n",
    "- `max_depth=4` - największa wysosość pojedynczego drzewa\n",
    "- `max_features=3` - ile najwięcej featerów może rozdzielać jedno drzewo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=20, max_depth=4,max_features=3, random_state=42)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "acc_rfc = accuracy_score(y_test, rfc_pred)\n",
    "rec_rfc = recall_score(y_test, rfc_pred)\n",
    "f1_rfc = f1_score(y_test, rfc_pred)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\".format(acc_rfc, rec_rfc, f1_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-superintendent",
   "metadata": {},
   "source": [
    "Kolejnym klasyfikatorem jest model opierający się na Stochastic Gradient Descent. Przy tym modelu wyspecyfikowałem następujące hiperparametry:\n",
    "- `loss=\"hinge\"` - określa funkcję straty\n",
    "- `penalty=\"l2\"` - regularyzacja l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "sgd_pred = sgd.predict(X_test)\n",
    "\n",
    "acc_sgd = accuracy_score(y_test, sgd_pred)\n",
    "rec_sgd = recall_score(y_test, sgd_pred)\n",
    "f1_sgd = f1_score(y_test, sgd_pred)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\".format(acc_sgd, rec_sgd, f1_sgd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-bones",
   "metadata": {},
   "source": [
    "Ostatnim modelem jest klasyfikator działający na SVM, zastosowałem w nim kernel `linear` - linowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel=\"linear\", random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "svc_pred = svc.predict(X_test)\n",
    "\n",
    "acc_svc = accuracy_score(y_test, svc_pred)\n",
    "rec_svc = recall_score(y_test, svc_pred)\n",
    "f1_svc = f1_score(y_test, svc_pred)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\".format(acc_svc, rec_svc, f1_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arr = [\n",
    "    [acc_logit, rec_logit, f1_logit],\n",
    "    [acc_rfc, rec_rfc, f1_rfc],\n",
    "    [acc_sgd, rec_sgd, f1_sgd], \n",
    "    [acc_svc, rec_svc, f1_svc]\n",
    "]\n",
    "\n",
    "results = pd.DataFrame(res_arr,columns = [\"Accuracy\", \"Recall\", \"F1-score\"], index=[\"Logistic Regression\", \"Random Forest\", \"Stochastic Gradient Descent\", \"SVM Classifier\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(18, 10))\n",
    "sns.barplot(data=results, y=\"Accuracy\",x=results.index,ax=axs[0])\n",
    "sns.barplot(data=results, y=\"Recall\",x=results.index,ax=axs[1])\n",
    "sns.barplot(data=results, y=\"F1-score\",x=results.index,ax=axs[2])\n",
    "axs[0].tick_params(axis=\"x\", rotation=90) \n",
    "axs[1].tick_params(axis=\"x\", rotation=90) \n",
    "axs[2].tick_params(axis=\"x\", rotation=90) \n",
    "axs[0].set_ylim([0,1]) \n",
    "axs[1].set_ylim([0,1]) \n",
    "axs[2].set_ylim([0,1]) \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-davis",
   "metadata": {},
   "source": [
    "Wybór najlepszego spośród tych modeli nie jest jednoznaczny jednak na pierwszy rzut oka SVM wydaje się być najlepszy, ewentualnie regresja logistyczna. Wybór zależy jednak również od tego, co jest dla nas najbardziej wartościowe. Jeżeli kosztowne dla nas będzie przewidzenie dnia suchego, podczas gdy faktycznie będzie padał deszcz, to powninniśmy optymalizować `recall`. Jeśli zaś sytuacja jest odwrotna: najwięcej kosztuje przewidzenie deszczu, gdy go nie będzie, to model powinniśmy optymalizować pod względem `precision`. Miarą, która daje nam najwięcej informacji o całokształcie modelu jest F1, więc jeśli wszystkie pomyłki są tak samo kosztowne, można podejmować decyzje na jej podstawie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
