{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD4 - Jan Smoleń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import dalex as dx\n",
    "import pickle\n",
    "np.random.seed = 46\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "import plotly\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aps=dx.datasets.load_apartments()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "aps=dx.datasets.load_apartments()\n",
    "Xa=aps.drop(\"district\", axis=1)\n",
    "ya=aps[\"district\"]\n",
    "aps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ mamy użyć SVM, to potraktujemy to zadanie jako klasyfikację ze względu na dzielnicę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines=pd.read_csv(\"winequality-red.csv\")\n",
    "wines[\"is_good\"] = wines.apply(lambda row: 1 if row.quality > 5 else 0, axis = 1)\n",
    "Xw = wines.drop([\"quality\", \"is_good\"], axis = 1)\n",
    "yw = wines[[\"is_good\"]]\n",
    "wines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramkę danych o winie potraktujemy jako zadanie klasyfikacji - czy wino jest dobre (ma ocenę powyżej 5) czy nie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział na zbiory testowe i treningowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(Xw, yw, test_size = 0.2, random_state = 1613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size = 0.2, random_state = 1613)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_a=SVC()\n",
    "svm_a.fit(Xa_train, ya_train)\n",
    "svm_w=SVC()\n",
    "svm_w.fit(Xw_train, yw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bazowe wyniki, bez standaryzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_preds=svm_a.predict(Xa_test)\n",
    "accuracy_score(ya_test, ya_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_preds=svm_w.predict(Xw_test)\n",
    "accuracy_score(yw_test, yw_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bazowe SVM na surowych zbiorach osiąga bardzo słabe wyniki. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Po standaryzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa=(Xa-Xa.mean())/Xa.std()\n",
    "Xw=(Xw-Xw.mean())/Xw.std()\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(Xw, yw, test_size = 0.2, random_state = 1613)\n",
    "Xa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size = 0.2, random_state = 1613)\n",
    "svm_a.fit(Xa_train, ya_train)\n",
    "svm_w.fit(Xw_train, yw_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_preds=svm_a.predict(Xa_test)\n",
    "accuracy_score(ya_test, ya_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_preds=svm_w.predict(Xw_test)\n",
    "accuracy_score(yw_test, yw_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samo standaryzowanie bardzo polepszyło wyniki naszych modeli - o ponad 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_a_tuned=SVC(random_state=42)\n",
    "c=[]  # wartości parametru C\n",
    "gamma=[]  #wartości parametru gamma \n",
    "for i in range(-4, 5):      # orientacyjne wartości na podstawie informacji znalezionych w internecie\n",
    "    c.append(10**i)\n",
    "for i in range(-4, 5):\n",
    "    gamma.append(10**i)\n",
    "gamma.append(\"auto\")\n",
    "gamma.append(\"scale\")\n",
    "params = [{'C': c,   \n",
    "        'gamma': gamma,\n",
    "        'kernel': [\"rbf\", \"linear\"]}]\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs_svm_a=RandomizedSearchCV(svm_a_tuned, param_distributions=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "#gs_svm=GridSearchCV(svm_a_tuned, param_grid=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "rs_svm_a.fit(Xa_train, ya_train)\n",
    "rs_svm_a.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm_a_acc=accuracy_score(gs_svm.predict(Xa_test),ya_test)\n",
    "rs_svm_a_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_w_tuned=SVC(random_state=42)\n",
    "c=[]  # wartości parametru C\n",
    "gamma=[]  #wartości parametru gamma \n",
    "for i in range(-4, 5):      # orientacyjne wartości na podstawie informacji znalezionych w internecie\n",
    "    c.append(10**i)\n",
    "for i in range(-4, 5):\n",
    "    gamma.append(10**i)\n",
    "gamma.append(\"auto\")\n",
    "gamma.append(\"scale\")\n",
    "params = [{'C': c,   \n",
    "        'gamma': gamma,\n",
    "        'kernel': [\"rbf\", \"linear\"]}]\n",
    "rs_svm_w=RandomizedSearchCV(svm_w_tuned, param_distributions=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "rs_svm_w.fit(Xw_train, yw_train)\n",
    "rs_svm_w.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_svm_w_acc=accuracy_score(gs_w_svm.predict(Xw_test),yw_test)\n",
    "rs_svm_w_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po dosyć długim czasie trenowania, dostaliśmy wyniki takie same albo nawet nieznacznie gorsze od bazowego SVM na wystandaryzowanych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
