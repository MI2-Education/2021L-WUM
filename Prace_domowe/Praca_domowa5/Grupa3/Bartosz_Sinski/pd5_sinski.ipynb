{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legendary-biotechnology",
   "metadata": {},
   "source": [
    "# Praca Domowa 5\n",
    "Bartosz Siński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-christmas",
   "metadata": {},
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"./src/clustering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-introduction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X.iloc[:,0], X.iloc[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-portable",
   "metadata": {},
   "source": [
    "### Metoda k-średnich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-morris",
   "metadata": {},
   "source": [
    "Znajdziemy najbardziej optymalną liczbę klastrów z użyciem metody Silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-wisconsin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "ss = []\n",
    "k = range(2, 15)\n",
    "for i in k:\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.predict(X)\n",
    "    score = silhouette_score(X,labels, random_state=42)\n",
    "    ss.append(score)\n",
    "plt.plot(k,ss,'bo-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-alloy",
   "metadata": {},
   "source": [
    "Widzimy, że najwyższa wartość Silhouette Score jest dla k=8. Zobaczmy jak wygląda wizualizacja przypisania naszych danych do ośmiu klastrów metodą k-średnich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "kmeans.fit(X)\n",
    "preds = kmeans.predict(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(X.iloc[:,0],X.iloc[:,1],c=preds,cmap=\"Set1\")\n",
    "plt.scatter(centers[:,0],centers[:,1],s=100,c=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-tower",
   "metadata": {},
   "source": [
    "### Hierarchiczna metoda aglomeracyjna z połączeniami Warda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-beast",
   "metadata": {},
   "source": [
    "Na poczatku znajdziemy optymalną liczbe klastrów przy użyciu mertyki Dunn Index. Poniższa implementacja pochodzi z https://github.com/jqmviegas/jqm_cvi/blob/master/jqmcvi/base.py. Wylicza ona indeks na podstawie najmniejszej odległości między punktami najbliższych klastrów i najwiekszej odległości pomiędzy klastrami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(ck, cl):\n",
    "    values = np.ones([len(ck), len(cl)])*10000\n",
    "    \n",
    "    for i in range(0, len(ck)):\n",
    "        for j in range(0, len(cl)):\n",
    "            values[i, j] = np.linalg.norm(ck[i]-cl[j])\n",
    "\n",
    "    return np.min(values)\n",
    "    \n",
    "def big_delta(ci):\n",
    "    values = np.zeros([len(ci), len(ci)])\n",
    "    \n",
    "    for i in range(0, len(ci)):\n",
    "        for j in range(0, len(ci)):\n",
    "            values[i, j] = np.linalg.norm(ci[i]-ci[j])\n",
    "            \n",
    "    return np.max(values)\n",
    "    \n",
    "def dunn(k_list):\n",
    "    deltas = np.ones([len(k_list), len(k_list)])*1000000\n",
    "    big_deltas = np.zeros([len(k_list), 1])\n",
    "    l_range = list(range(0, len(k_list)))\n",
    "    \n",
    "    for k in l_range:\n",
    "        for l in (l_range[0:k]+l_range[k+1:]):\n",
    "            deltas[k, l] = delta(k_list[k], k_list[l])\n",
    "        \n",
    "        big_deltas[k] = big_delta(k_list[k])\n",
    "\n",
    "    di = np.min(deltas)/np.max(big_deltas)\n",
    "    return di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-surname",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "scores = []\n",
    "k = range(2,20)\n",
    "for i in k:\n",
    "    labels = pd.DataFrame(AgglomerativeClustering(n_clusters=i).fit_predict(X))\n",
    "    labels.columns=[\"Label\"]\n",
    "    pred = pd.concat([X,labels],axis=1)\n",
    "    clusters = []\n",
    "    for j in range(0,i):\n",
    "        obs = pred.loc[pred.Label==j]\n",
    "        clusters.append(obs.iloc[:,[0,1]].values)\n",
    "    scores.append(dunn(clusters))\n",
    "plt.plot(k,scores,'bo-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Dunn Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-thirty",
   "metadata": {},
   "source": [
    "Najwyższe wartości indeksu Dunna są dla k = [6, 7, 8]. Zobaczymy jak będą wyglądać klastry naszych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3,figsize=(5,15))\n",
    "pred1 = AgglomerativeClustering(n_clusters=6).fit_predict(X)\n",
    "pred2 = AgglomerativeClustering(n_clusters=7).fit_predict(X)\n",
    "pred3 = AgglomerativeClustering(n_clusters=8).fit_predict(X)\n",
    "axs[0].scatter(X.iloc[:,0],X.iloc[:,1],c=pred1,cmap=\"Set1\")\n",
    "axs[0].set_title(\"k = 6\")\n",
    "axs[1].scatter(X.iloc[:,0],X.iloc[:,1],c=pred2,cmap=\"Set1\")\n",
    "axs[1].set_title(\"k = 7\")\n",
    "axs[2].scatter(X.iloc[:,0],X.iloc[:,1],c=pred3,cmap=\"Set1\")\n",
    "axs[2].set_title(\"k = 8\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
