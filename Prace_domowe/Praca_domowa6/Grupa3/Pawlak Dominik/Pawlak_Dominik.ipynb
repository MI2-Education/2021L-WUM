{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "def plot_gallery(title, images, n_col=3, n_row=2, cmap=plt.cm.gray, img_shape=(64,64)):\n",
    "    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
    "    plt.suptitle(title, size=16)\n",
    "    for i, comp in enumerate(images):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        vmax = max(comp.max(), -comp.min())\n",
    "        plt.imshow(comp.reshape(img_shape), cmap=cmap,\n",
    "                   interpolation='nearest',\n",
    "                   vmin=-vmax, vmax=vmax)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)\n",
    "    \n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True,\n",
    "                                random_state=RandomState(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True)\n",
    "pca = PCA().fit(faces)\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_)+1), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.title(\"PCA explained variance\")\n",
    "plt.axhline(y=0.90, color=\"y\")\n",
    "plt.axvline(x=70, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-balance",
   "metadata": {},
   "source": [
    "Zastosuję PCA dla 70 komponentów, ponieważ osiągnę wówczas około 90% wyjaśnialnej wariancji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=70)\n",
    "faces_pca = pca.fit_transform(faces)\n",
    "\n",
    "print(f\"Stopień konwersji: {faces[0].size / faces_pca[0].size}\")\n",
    "IT = pca.inverse_transform(faces_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(\"Random Olivetti faces\", faces[:10], n_col = 5, n_row=2)\n",
    "plot_gallery(\"Random Olivetti faces after PCA and Inverse Transformation\", IT[:10], n_col = 5, n_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def RMSE(mod):\n",
    "    rmse = [0] * 400\n",
    "    for i, j, k in zip(faces, mod, range(400)):\n",
    "        rmse[k] = mean_squared_error(i, j, squared=False)\n",
    "\n",
    "    print(f\"Uśredniony błąd RMSE: {np.mean(rmse)}\")\n",
    "\n",
    "RMSE(IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana koloru\n",
    "faces_minus = - faces\n",
    "\n",
    "plot_gallery(\"Random Olivetti faces\", faces_minus[:10], n_col = 5, n_row=2)\n",
    "RMSE(faces_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odwrocone do gory nogami\n",
    "faces_flip = []\n",
    "\n",
    "for i in faces: faces_flip.append(i[::-1])\n",
    "plot_gallery(\"Random Olivetti faces\", faces_flip[:10], n_col = 5, n_row=2)\n",
    "RMSE(faces_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zwiekszony kontrast\n",
    "faces_mul = 10 * faces\n",
    "\n",
    "plot_gallery(\"Random Olivetti faces\", faces_mul[:10], n_col = 5, n_row=2)\n",
    "RMSE(faces_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyciemnienie\n",
    "faces_dark = faces - 2\n",
    "\n",
    "plot_gallery(\"Random Olivetti faces\", faces_dark[:10], n_col = 5, n_row=2)\n",
    "RMSE(faces_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozjasnianie\n",
    "faces_light = faces + 2\n",
    "\n",
    "plot_gallery(\"Random Olivetti faces\", faces_light[:10], n_col = 5, n_row=2)\n",
    "RMSE(faces_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-senior",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "Najmniejszy błąd RMSE osiągnęły zdjęcia po transformacji odwrotnej. Mimo znaczącego stopnia kompresji, nie były one dużo bardziej rozmazane. Osoby na tych zdjęciach miały obwódki wokół oczu, jakby okulary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
