{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "explicit-stable",
   "metadata": {},
   "source": [
    "# Praca Domowa 6\n",
    "Bartosz Siński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "np.set_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-fruit",
   "metadata": {},
   "source": [
    "## Załadowanie danych i rysowanie obrazów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-surname",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True,\n",
    "                                random_state=1613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-accordance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_id = [355,145,267,289,375,1]\n",
    "imshape = (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-convention",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(4+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-vitamin",
   "metadata": {},
   "source": [
    "## Przygotowanie PCA i dobranie liczby składowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-regulation",
   "metadata": {},
   "source": [
    "Nasze wartości znajduja się w przediale [0,1] więc nie ma potrzeby ich skalowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-genetics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(faces)\n",
    "variance = np.cumsum(pca.explained_variance_ratio_)[0:400]\n",
    "plt.plot(range(400),variance)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[199]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-rover",
   "metadata": {},
   "source": [
    "Widzimy, że przy pozostawieniu 200 komponentów składowych mamy jeszcze zachowane prawie 98% wariancji więc wybierzemy właśnie te liczby komponentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-season",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca200 = PCA(n_components=200).fit(faces)\n",
    "faces_reduced = pca200.transform(faces)\n",
    "print('Stopień kompresji: '+ str(faces.shape[1]/faces_reduced.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_pca = pca200.inverse_transform(faces_reduced)\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_pca[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_pca[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "for i in range(6):\n",
    "    print('Błąd rekonstrukcji w postaci RMSE dla obrazka ' + str(i+1) +\" = \" + str(mean_squared_error(faces[images_id[i]],faces_pca[images_id[i]])))\n",
    "print('Średni błąd rekonstrukcji w postaci RMSE dla wybranych obrazków: '+ str(mean_squared_error(faces[images_id],faces_pca[images_id])))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-digit",
   "metadata": {},
   "source": [
    "Przede wszystkim zdjęcia wydają się być mniej ostre. Dodatkowo wsród osób bez okularów pojawiły się obramowania wokół oczu. Najmniejszy błąd przy rekonstrukcji był dla zdjęcia 3, na którym znajduje się kobieta o gładkich rysach bez okularów, a największy dla zdjęcia 4 gdzie znajduje się starszy pan w okularach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-employee",
   "metadata": {},
   "source": [
    "## Zmodyfikowane obrazy na wcześniej wyuczonym modelu\n",
    "### Obrazy obrócone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = -np.sort(-np.arange(4096))\n",
    "faces_reversed = faces[:,order]\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_reversed[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_reversed[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-bolivia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "faces_r = pca200.transform(faces_reversed)\n",
    "faces_r = pca200.inverse_transform(faces_r)\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_r[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_r[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-essence",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Błąd rekonstrukcji w postaci RMSE dla wybranych obrazków: '+ str(mean_squared_error(faces_reversed[images_id],faces_r[images_id])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-hardwood",
   "metadata": {},
   "source": [
    "Z PCA nauczonym na normalnych obrazach, odwrócone obrazy po rekonstrukcji w żaden sposób nie przypominają oryginałów. Widać za to jeszcze bardziej \"dorysowywanie\" okularów przy rekonstrukcji. Błędy RMSE są także ponad 10 razy większe niz poprzednio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-dream",
   "metadata": {},
   "source": [
    "## Obrazy odwrócone w poziomie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-simple",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = np.arange(0,4096)\n",
    "order = np.split(order,64)\n",
    "def fun(arr):\n",
    "    return(-np.sort(-arr))\n",
    "order = np.apply_along_axis(fun, 1, order)\n",
    "order = np.reshape(order,(1,4096))[0]\n",
    "faces_reversed2 = faces[:,order]\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_reversed2[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_reversed2[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-practice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "faces_r2 = pca200.transform(faces_reversed2)\n",
    "faces_r2 = pca200.inverse_transform(faces_r2)\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_r2[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_r2[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Błąd rekonstrukcji w postaci RMSE dla wybranych obrazków: '+ str(mean_squared_error(faces_reversed2[images_id],faces_r2[images_id])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-dream",
   "metadata": {},
   "source": [
    "Błędy rekonstrukcji są mniejsze niż w przypadków obrazów obróconych o 180 stopni jednak nadal są ponad 5 razy większe niż w przypadku oryginalnych zdjęć. Obrazy mocno różnią się od oryginałów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-verification",
   "metadata": {},
   "source": [
    "### Obrazy przyciemnione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_dimmed = faces - 0.2\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_dimmed[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_dimmed[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_d = pca200.transform(faces_dimmed)\n",
    "faces_d = pca200.inverse_transform(faces_d)\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_d[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_d[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Błąd rekonstrukcji w postaci RMSE dla wybranych obrazków: '+ str(mean_squared_error(faces_dimmed[images_id],faces_d[images_id])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-footage",
   "metadata": {},
   "source": [
    "### Obrazy rozjaśnione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_bright = faces + 0.2\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_bright[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_bright[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_b = pca200.transform(faces_bright)\n",
    "faces_b = pca200.inverse_transform(faces_b)\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_b[images_id[i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_b[images_id[3+i]].reshape(imshape),vmin=0, vmax=1)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Błąd rekonstrukcji w postaci RMSE dla wybranych obrazków: '+ str(mean_squared_error(faces_bright[images_id],faces_b[images_id])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-expansion",
   "metadata": {},
   "source": [
    "Zarówno przyciemnone i jak i rozjaśnione obrazy zostały zrekonstruowane z podobną jakością jak zdjęcia oryginalne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-checklist",
   "metadata": {},
   "source": [
    "## Obrazy z  odwróconymi kolorami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_color = -faces \n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_color[images_id[i]].reshape(imshape),vmin=-1, vmax=0)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_color[images_id[3+i]].reshape(imshape),vmin=-1, vmax=0)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_c = pca200.transform(faces_color)\n",
    "faces_c = pca200.inverse_transform(faces_c)\n",
    "fig, axs = plt.subplots(ncols=3,nrows=2,figsize=(15,10))\n",
    "for i in range(3):\n",
    "    axs[0,i].imshow(faces_c[images_id[i]].reshape(imshape),vmin=-1, vmax=0)\n",
    "    axs[0,i].set_title(i+1)\n",
    "    axs[1,i].imshow(faces_c[images_id[3+i]].reshape(imshape),vmin=-1, vmax=0)\n",
    "    axs[1,i].set_title(i+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Błąd rekonstrukcji w postaci RMSE dla wybranych obrazków: '+ str(mean_squared_error(faces_color[images_id],faces_c[images_id])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-poster",
   "metadata": {},
   "source": [
    "Odwrócenie kolorów zdecydowanie obniżyło jakość rekonstrukcji obrazów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-weapon",
   "metadata": {},
   "source": [
    "### Wnioski\n",
    "Rezultaty transformacji odwrotnej obrazów z 200 komponentów do 4096 okazały się bardzo zadowalające. W przypadku większości obrazów oryginalnych, do których fitowaliśmy PCA, ciężko było znaleźć różnice pomiędzy oryginałami, a zrekonstruowanymi obrazami. Zaskakujące okazało się to, że obrazy pociemnione i rozjaśnione zostały zrekonstruowane prawie tak samo dobrze jak oryginały. W przypadku bardziej zniekształcających obraz transformacji (np. obrót obrazu o 180 stopni) wyniki rekonstrukcji były zdecydowanie gorsze. Nasza metoda odtwarzania była wrażliwa na okulary i na większości obrazów je dorysowywała. PCA mogłoby więc posłużyć do określenia w prosty sposób czy wśród naszych obrazów są zdjęcia ludzi w okularach. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
